&emsp;
# 2 非线性最小二乘
我们先来考虑一个简单的最小二乘问题：

$$\min_x\frac{1}{2}||f(\pmb{x})||^2_2$$

这里自变量 $x ∈ \mathbb{R}^n$，$f$ 是任意一个非线性函数，我们设它有 $m$ 维：$f(x) ∈ \mathbb{R}^m$。下面讨论如何求解这样一个优化问题。

如果 $f$ 是个数学形式上很简单的函数，那问题也许可以用解析形式来求。令目标函数的导数为零，然后求解 $x$ 的最优值，就和一个求二元函数的极值一样：



$$\begin{equation}
\frac{ \mathrm{d} \left( \frac{1}{2}{\left\| {f\left( \bm{x} \right)} \right\|^2_2} \right) }{ \mathrm{d} \bm{x} } = \bm{0}.
\end{equation}$$

解此方程，就得到了导数为零处的极值。它们可能是极大、极小或鞍点处的值，只要挨个儿比较它们的函数值大小即可。

但是，这个方程是否容易求解呢？这取决于 $f$ 导函数的形式。在 SLAM 中，我们使用李代数来表示机器人的旋转和位移。尽管我们在李代数章节讨论了它的导数形式，但这不代表我们就能够顺利求解上式这样一个复杂的非线性方程。

对于不方便直接求解的最小二乘问题，我们可以用迭代的方式，从一个初始值出发，不断地更新当前的优化变量，使目标函数下降。具体步骤可列写如下：

1. 给定某个初始值 $x_0$
2. 对于第 $k$ 次迭代，寻找一个增量 $∆\pmb{x}_k$，使得 $∥f (\pmb{x}_k + ∆\pmb{x}_k)∥^2_2$ 达到极小值
3. 若 $∆\pmb{x}_k$ 足够小，则停止
4. 否则，令 $\pmb{x}_k+1 = \pmb{x}_k + ∆\pmb{x}_k$，返回 2.

这让求解导函数为零的问题，变成了一个不断寻找梯度并下降的过程。直到某个时刻增量非常小，无法再使函数下降。此时算法收敛，目标达到了一个极小，我们完成了寻找极小值的过程。在这个过程中，我们只要找到迭代点的梯度方向即可，而无需寻找全局导函数为零的情况。

接下来的问题是，增量 $∆\pmb{x}_k$ 如何确定？—— 实际上，研究者们已经花费了大量精力探索增量的求解方式。我们将介绍两类办法，它们用不同的手段来寻找这个增量。目前这两种方法在视觉 SLAM 的优化问题上也被广泛采用，大多数优化库都可以使用它们。





