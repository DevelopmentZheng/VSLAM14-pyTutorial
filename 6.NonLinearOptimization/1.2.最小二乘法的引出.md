&emsp;
## 1.2 最小二乘法的引出
- 最小二乘跟最大似然估计本质上是同一个东西
>高斯建模
- 那么如何求最大似然估计呢？我们说，在高斯分布的假设下，最大似然能够有较简单的形式。回顾观测模型，对于某一次观测：

    $$z_{k,j} = h(\pmb{y}_j，\pmb{x}_k) + \pmb{v}_{k, j}$$
    - $\pmb{z}_{k,j}$：观测数据
    - $\pmb{y}_j$：路标点
    - $\pmb{x}_k$：位置
    - $\pmb{v}_{k,j}$ 是这次观测里的噪声

    由于我们假设了噪声项 $\pmb{v}_k ∼ N (0, \pmb{Q}_{k,j} )$，所以观测数据的条件概率为：

    $$P(z_{j,k} | \pmb{x}_k，\pmb{y}_j) = N (h(\pmb{y}_j，\pmb{x}_k), \pmb{Q}_{k,j})$$

    它依然是一个高斯分布。为了计算使它最大化的 $\pmb{x}_k, \pmb{y}_j$，我们往往使用最小化负对数的方式，来求一个高斯分布的最大似然。

&emsp;
>最大似然估计
- 高斯分布在负对数下有较好的数学形式。考虑一个任意的高维高斯分布 $\pmb{x} ∼ N(\pmb{\mu}, Σ)$，它的概率密度函数展开形式为:

    $$P(\pmb{x}) = \frac{1}{\sqrt{(2\pi)^N det(\Sigma)}}exp\Big(-\frac{1}{2}(\pmb{x} - \pmb{\mu})^T\Sigma^{-1}(\pmb{x} - \pmb{\mu}) \Big)$$

    取它的负对数，则变为：

    $$-ln(P(\pmb{x})) = \frac{1}{2}ln \Big( (2\pi)^N det(\Sigma) \Big) + \frac{1}{2}(\pmb{x} - \pmb{\mu})^T\Sigma^{-1}(\pmb{x} - \pmb{\mu})$$

    对原分布求最大化相当于对负对数求最小化。在最小化上式的 $\pmb{x}$ 时，第一项与 $\pmb{x}$ 无关，可以略去。于是，只要最小化右侧的二次型项
    $$arg\min\frac{1}{2}(\pmb{x} - \pmb{\mu})^T\Sigma^{-1}(\pmb{x} - \pmb{\mu})$$
    就得到了对状态的最大似然估计。

&emsp;
>最小二乘
- 代入 SLAM 的观测模型，相当于我们在求：

    $$\pmb{x}* = arg\min \Big( \big(z_{k，j} - h(\pmb{x}_k，\pmb{y}_j)\big)^T \pmb{Q}^{-1}_{k，j} \big(z_{k，j} - h(\pmb{x}_k，\pmb{y}_j)\big)\Big)$$

    我们发现，该式等价于最小化噪声项（即误差）的平方（$Σ$ 范数意义下）。因此，对于所有的运动和任意的观测，我们定义数据与估计值之间的误差：

    $$\begin{cases}e_{v，k} = \pmb{x}_k-f(\pmb{x}_{k-1}，\pmb{u}_k) & 运动方程\\
    e_{y，j，k} = z_{k，j}-h(\pmb{x}_{k}，\pmb{y}_j)& 观测方程\end{cases} $$

    并求运动方程和观测方程的误差平方之和（范数/二次型/Sigma范数）：

    $$J(\pmb{x}) = \sum_k \pmb{e}^T_{v,k}\pmb{R}^{-1}_k \pmb{e}_{v,k} + \sum_k\sum_j \pmb{e}^T_{y,k,j}\pmb{Q}^{-1}_{k,j}\pmb{e}_{y,k,j}\quad (6.12)$$

    这就得到了一个 `总体`意义下的`最小二乘问题（Least Square Problem）`。

&emsp;
>非线性优化过程
- 我们明白它的最优解等价于状态的最大似然估计。

    直观来讲，由于噪声的存在，当我们把估计的轨迹与地图代入 SLAM 的运动、观测方程中时，它们并不会完美的成立。这时候怎么办呢？我们把状态的估计值进行微调，使得整体的误差下降一些。当然这个下降也有限度，它一般会到达一个极小值。
    
    这就是一个典型非线性优化的过程。



&emsp;
>最小二乘的结构
- 仔细观察式（6.12），我们发现 SLAM 中的最小二乘问题具有一些特定的结构：
- 首先，整个问题的目标函数由许多个误差的（加权的）平方和组成。
    
    虽然总体的状态变量维数很高，但每个误差项都是简单的，仅与一两个状态变量有关。例如运动误差只与 $\pmb{x}_{k-1}， \pmb{x}_k$ 有关，观测误差只与 $\pmb{x}_k， \pmb{y}_j$ 有关。
    
    每个误差项是一个小规模的约束，我们之后会谈论如何对它们进行线性近似，最后再把这个误差项的小雅可比矩阵块放到整体的雅可比矩阵中。
    
    由于这种做法，我们称每个误差项对应的优化变量为 `参数块（Parameter Block）`

- 整体误差由很多小型误差项之和组成的问题，其增量方程的求解会具有一定的稀疏性（会在第十讲详细讲解），使得它们在大规模时亦可求解。
- 其次，如果使用李代数表示，则该问题是无约束的最小二乘问题。但如果用旋转矩阵（变换矩阵）描述位姿，则会引入旋转矩阵自身的约束（旋转矩阵必须是正交阵且行列式为 1）。额外的约束会使优化变得更困难。这体现了李代数的优势。
- 最后，我们使用了平方形式（二范数）度量误差，它是直观的，相当于欧氏空间中距离的平方。但它也存在着一些问题，并且不是唯一的度量方式。我们亦可使用其他的范数构建优化问题。

现在，我们要介绍如何求解这个最小二乘问题。本章将介绍非线性优化的基本知识，特别地，针对这样一个通用的无约束非线性最小二乘问题，探讨它是如何求解的。在后续几章，我们会大量使用本章的结果，详细讨论它在 SLAM 前端、后端中的应用。