&emsp;
# 1.2 ORB 特征
<div align="center">
    <image src="./imgs/7.1.2-1.png" width = 600>
</div>
&emsp;

ORB 特征亦由 `关键点` 和 `描述子` 两部分组成。
- 关键点：Oriented FAST，是一种改进的 FAST 角点，什么是 FAST 角点我们将在下文介绍
- 描述子：BRIEF（Binary Robust Independent Elementary Features）。

因此，提取 ORB 特征分为两个步骤：
1. `FAST 角点提取`：找出图像中的” 角点”。相较于原版的 FAST, ORB 中计算了特征
点的主方向，为后续的 BRIEF 描述子增加了旋转不变特性。
2. `BRIEF 描述子`：对前一步提取出特征点的周围图像区域进行描述。
下面我们分别介绍 FAST 和 BRIEF。

&emsp;
## （1）FAST 角点
<div align="center">
    <image src="./imgs/7.1.2-2.png" width = 400>
</div>
&emsp;

>FAST 检测的过程
- $FAST$ 是一种角点，主要检测局部像素灰度变化明显的地方，以速度快著称。它的思想是：如果一个像素与它邻域的像素差别较大（过亮或过暗）, 那它更可能是角点。相比于其他角点检测算法，$FAST$ 只需比较像素亮度的大小，十分快捷。它的检测过程如下（见图 7-3 ）：
    1. 在图像中选取像素 $p$，假设它的亮度为 $Ip$
    2. 设置一个阈值 $T$(比如 $Ip$ 的 $20%$)
    3. 以像素 $p$ 为中心, 选取半径为 $3$ 的圆上的 $16$ 个像素点。
    4. 假如选取的圆上，有连续的 $N$ 个点的亮度大于 $Ip + T$ 或小于 $Ip - T$，那么像素 p 可以被认为是特征点 ($N$ 通常取 $12$，即为 $FAST-12$。其它常用的 $N$ 取值为 $9$ 和 $11$，他们分别被称为 $FAST-9$，$FAST-11$)
    5. 循环以上四步，对每一个像素执行相同的操作

&emsp;
>FAST 检测的优化
- 在 $FAST-12$ 算法中，为了更高效，可以添加一项预测试操作，以快速地排除绝大多数不是角点的像素。具体操作为，对于每个像素，直接检测邻域圆上的第 $1，5，9，13$ 个像素的亮度。只有当这四个像素中有三个同时大于 $Ip + T$ 或小于 $Ip - T$ 时，当前像素才有可能是一个角点，否则应该直接排除。这样的预测试操作大大加速了角点检测。

- 此外，原始的 FAST 角点经常出现“扎堆”的现象。所以在第一遍检测之后，还需要用 `非极大值抑制（Non-maximal suppression）`，在一定区域内仅保留响应极大值的角点，避免角点集中的问题。

&emsp;
>ORB 对 FAST 的改进
- $FAST$ 特征点的计算仅仅是比较像素间亮度的差异，速度非常快，但它也有一些问题。
    - 首先，$FAST$ 特征点数量很大且不确定，而我们往往希望对图像提取固定数量的特征。因此，在 $ORB$ 中，对原始的 $FAST$ 算法进行了改进。我们可以指定最终要提取的角点数量 $N$，对原始 $FAST$ 角点分别计算 $Harris$ 响应值，然后选取前 $N$ 个具有最大响应值的角点，作为最终的角点集合。

    - 其次，$FAST$ 角点不具有方向信息。而且，由于它固定取半径为 3 的圆，存在尺度问题：
    
        远处看着像是角点的地方，接近后看可能就不是角点了。针对 FAST 角点不具有方向性和尺度的弱点，ORB 添加了尺度和旋转的描述。尺度不变性由构建图像金字塔（金字塔是指对图像进行不同层次的降采样，以获得不同分辨率的图像），并在金字塔的每一层上检测角点来实现。而特征的旋转是由 `灰度质心法（Intensity Centroid）`实现的。


&emsp;
>灰度质心法（Intensity Centroid）
- 质心是指以图像块灰度值作为权重的中心。其具体操作步骤如下 [35]：Measuring corner properties
    1. 在一个小的图像块 $B$ 中，定义图像块的矩为：
    $$m_{pq} = \sum_{x,y\ \in\ B} x^p y^qI(x, y)，\quad p,q = \{0,1\}$$
    2. 通过矩可以找到图像块的质心：
    $$C = (\frac{m_{10}}{m_{00}}，\frac{m_{01}}{m_{00}})$$
    3. 连接图像块的几何中心 $O$ 与质心 $C$，得到一个方向向量 $\overrightarrow{OC}$，于是特征点的方向可以定义为：
    $$\theta = arctan(m_{01} / m_{10})$$

通过以上方法，$FAST$ 角点便具有了尺度与旋转的描述，大大提升了它们在不同图像之间表述的鲁棒性。所以在 $ORB$ 中，把这种改进后的 $FAST$ 称为 $Oriented\ \ FAST$。


&emsp;
## （2）BRIEF 描述子

在提取 $Oriented\ \ FAST$ 关键点后，我们对每个点计算其描述子。$ORB$ 使用改进的 $BRIEF$ 特征描述。我们先来讲 $BRIEF$ 是什么。

$BRIEF$ 是一种二进制描述子，它的描述向量由许多个 $0$ 和 $1$ 组成，这里的 $0$ 和 $1$ 编码了关键点附近两个像素（比如说 $p$ 和 $q$）的大小关系：
- 如果 $p$ 比 $q$ 大，则取 $1$，反之就取 $0$。

如果我们取了 $128$ 个这样的 $p$, $q$，最后就得到 $128$ 维由 $0$，$1$ 组成的向量。

那么，$p$ 和 $q$ 如何选取呢？在作者原始的论文中给出了若干种挑选方法，大体上都是按照某种概率分布，随机地挑选 $p$ 和 $q$ 的位置，读者可以阅读 $BRIEF$ 论文或 $OpenCV$ 源码以查看它的具体实现 `[34] Brief: Binary robust independent elementary features`。


$BRIEF$ 使用了随机选点的比较，速度非常快，而且由于使用了二进制表达，存储起来也十分方便，适用于实时的图像匹配。原始的 $BRIEF$ 描述子 `不具有旋转不变性` 的，因此在图像发生旋转时容易丢失。而 $ORB$ 在 $FAST$ 特征点提取阶段计算了关键点的方向，所以可以利用方向信息，计算了旋转之后的 $Steer BRIEF$ 特征，使 $ORB$ 的描述子具有较好的旋转不变性。

由于考虑到了旋转和缩放，使得 $ORB$ 在平移、旋转、缩放的变换下仍有良好的表现。同时，$FAST$ 和 $BRIEF$ 的组合也非常的高效，使得 $ORB$ 特征在实时 $SLAM$ 中非常受欢迎。我们在图 7-2 中展示了一张图像提取 $ORB$ 之后的结果，下面来介绍如何在不同的图像之间进行特征匹配。

&emsp;
## （3）特征匹配

<div align="center">
    <image src="./imgs/7.1.3-1.png" width = 600>
</div>
&emsp;

特征匹配是视觉 $SLAM$ 中极为关键的一步，宽泛地说，特征匹配解决了 $SLAM$ 中的 `数据关联问题（data association）`，即确定当前看到的路标与之前看到的路标之间的对应关系。通过对图像与图像，或者图像与地图之间的描述子进行准确的匹配，我们可以为后续的姿态估计，优化等操作减轻大量负担。

>误匹配问题
- 然而，由于图像特征的局部特性，误匹配的情况广泛存在，而且长期以来一直没有得到有效解决，目前已经成为视觉 SLAM 中制约性能提升的一大瓶颈。部分原因是因为场景中经常存在大量的重复纹理，使得特征描述非常相似。在这种情况下，仅利用局部特征解决误匹配是非常困难的。

    不过，让我们先来看正确匹配的情况，等做完实验再回头去讨论误匹配问题。

&emsp;
>暴力匹配（Brute-Force Matcher）
- 考虑两个时刻的图像。如果在图像 $I_t$ 中提取到特征点 $x^m_t ，m = 1, 2, ..., M$，在图像 $I_{t+1}$ 中提取到特征点 $x^n_{t+1}，n = 1, 2, ..., N$，如何寻找这两个集合元素的对应关系呢？

    最简单的特征匹配方法就是 `暴力匹配（Brute-Force Matcher）`。即对每一个特征点 $x^m_t$ ，与所有的 $x^n_{t+1}$ 测量描述子的距离，然后排序，取最近的一个作为匹配点。

&emsp;
>汉明距离（Hamming distance）
- 描述子距离表示了两个特征之间的相似程度，不过在实际运用中还可以取不同的距离度量范数。
    
    - 对于`浮点类型`的描述子，使用欧氏距离进行度量即可
    - 对于`二进制`的描述子（比如 $BRIEF$ 这样的），我们往往使用 `汉明距离（Hamming distance）` 做为度量——两个二进制串之间的汉明距离，指的是它们不同位数的个数。

>特征匹配过程
- 第一步：检测 $Oriented\ FAST$ 角点位置
- 第二步：根据角点位置计算 $BRIEF$ 描述子
- 第三步：对两幅图像中的 $BRIEF$ 描述子进行匹配，使用 $Hamming$ 距离
- 第四步：匹配点对筛选
```c++
void find_feature_matches ( 
    const Mat& img_1, const Mat& img_2,
    // 将匹配结果存储到下面三个变量中
    std::vector<KeyPoint>& keypoints_1,
    std::vector<KeyPoint>& keypoints_2,
    std::vector< DMatch >& matches )
{
    //-- 初始化
    Mat descriptors_1, descriptors_2;
    // used in OpenCV3 
    Ptr<FeatureDetector> detector = ORB::create();
    Ptr<DescriptorExtractor> descriptor = ORB::create();
    // use this if you are in OpenCV2 
    // Ptr<FeatureDetector> detector = FeatureDetector::create ( "ORB" );
    // Ptr<DescriptorExtractor> descriptor = DescriptorExtractor::create ( "ORB" );
    Ptr<DescriptorMatcher> matcher  = DescriptorMatcher::create ( "BruteForce-Hamming" );
    //-- 第一步:检测 Oriented FAST 角点位置
    detector->detect ( img_1,keypoints_1 );
    detector->detect ( img_2,keypoints_2 );

    //-- 第二步:根据角点位置计算 BRIEF 描述子
    descriptor->compute ( img_1, keypoints_1, descriptors_1 );
    descriptor->compute ( img_2, keypoints_2, descriptors_2 );

    //-- 第三步:对两幅图像中的 BRIEF 描述子进行匹配，使用 Hamming 距离
    vector<DMatch> match;
    BFMatcher matcher ( NORM_HAMMING );
    matcher->match ( descriptors_1, descriptors_2, match );

    //-- 第四步:匹配点对筛选
    double min_dist=10000, max_dist=0;

    //找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离
    for ( int i = 0; i < descriptors_1.rows; i++ )
    {
        double dist = match[i].distance;
        if ( dist < min_dist ) min_dist = dist;
        if ( dist > max_dist ) max_dist = dist;
    }

    printf ( "-- Max dist : %f \n", max_dist );
    printf ( "-- Min dist : %f \n", min_dist );

    //当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限.
    for ( int i = 0; i < descriptors_1.rows; i++ )
    {
        if ( match[i].distance <= max ( 2*min_dist, 30.0 ) )
        {
            matches.push_back ( match[i] );
        }
    }
}
```

&emsp;
>快速近似最近邻（FLANN）算法
- 然而，当特征点数量很大时，暴力匹配法的运算量将变得很大，特别是当我们想要匹配一个帧和一张地图的时候。这不符合我们在 $SLAM$ 中的实时性需求。此时 `快速近似最近邻（FLANN）算法` 更加适合于匹配点数量极多的情况。

    由于这些匹配算法理论已经成熟，而且实现上也已集成到 $OpenCV$，所以我们这里就不再描述它的技术细节了。感兴趣的读者，可以阅读 `[36]：Fast approximate nearest neighbors with automatic algorithm configuration`. 作为参考