&emsp;
# 2.3 SLAM 问题的数学描述


假设小萝卜正携带着某种传感器在未知环境里运动，怎么用数学语言描述这件事呢？

首先，由于相机通常是在某些时刻采集数据的，所以我们也只关心这些时刻的位置和地图。
- 把一段连续时间的运动变成了离散时刻 $t = 1, 2,..., K$ 当中发生的事情
- 在这些时刻，用 $\pmb{x}$ 表示小萝卜自身的位置。于是各时刻的位置就记为$x_1, 2, ..., x_K$，它们构成了小萝卜的轨迹。
- 地图方面，我们设地图是由许多个路标（Landmark）组成的，而每个时刻，传感器会测量到一部分路标点，得到它们的观测数据。不妨设路标点一共有 $N$ 个，用 $y_1, y_2,..., y_N$表示它们。

在这样设定中，“小萝卜携带着传感器在环境中运动”，由如下两件事情描述：
1. 什么是运动？我们要考虑从 $k-1$ 时刻到 $k$ 时刻，小萝卜的位置 $\pmb{x}$ 是如何变化的。
2. 什么是观测？假设小萝卜在 $k$ 时刻，于 $x_k$ 处探测到了某一个路标 $\pmb{y}_j$，我们要考虑这件事情是如何用数学语言来描述的。

&emsp;
## 1 运动方程

先来看运动。通常，机器人会携带一个测量自身运动的传感器，比如说`码盘`或`惯性传感器`。这个传感器可以测量有关运动的读数，但不一定直接是位置之差，还可能是`加速度`、`角速度`等信息。然而，无论是什么传感器，我们都能使用一个通用的、抽象的数学模型：
$$\pmb{x}_k = f(\pmb{x}_{k-1}, \pmb{u}_k, \pmb{w}_k)$$

- $\pmb{u}_k$：是运动传感器的读数（有时也叫输入）
- $\pmb{w}_k$ 为噪声

注意到，我们用一个一般函数 $f$ 来描述这个过程，而不具体指明 $f$ 的作用方式。这使得整个函数可以指代任意的运动传感器，成为一个通用的方程，而不必限定于某个特殊的传感器上。我们把它称为运动方程。

&emsp;
## 2 观测方程

与运动方程相对应，还有一个观测方程。观测方程描述的是，当小萝卜在 $\pmb{x}_k$ 位置上看到某个路标点 $\pmb{y}_j$，产生了一个观测数据 $\pmb{z}_{k,j}$。同样，我们用一个抽象的函数 h 来描述这个关系：

$$\pmb{z}_{k,j} = h(\pmb{y}_j , \pmb{x}_k, \pmb{v}_{k,j})$$
- $\pmb{v}_{k,j}$ 是这次观测里的噪声

由于观测所用的传感器形式更多，这里的观测数据 $z$ 以及观测方程 $h$ 也许多不同的形式。

读者或许会说，我们用的函数 $f, h$，似乎并没有具体地说明运动和观测是怎么回事？同时，这里的 $x,y,z$ 又是什么东西呢？事实上，根据小萝卜的真实运动和传感器的种类，存在着若干种参数化方式（Parameterization）。

什么叫参数化呢？举例来说，假设小萝卜在平面中运动，那么，它的位姿由`两个位置`和`一个转角`来描述，即 
$$\pmb{x}_k = [x, y, θ]^T_k$$ 

同时，运动传感器能够测量到小萝卜在每两个时间间隔位置和转角的变化量 
$$\pmb{u}k = [∆x, ∆y, ∆θ]^T_k$$ 

那么，此时运动方程就可以具体化为：
$$
\begin{bmatrix} x \\ y \\ \theta\end{bmatrix}_k =
\begin{bmatrix} x \\ y \\ \theta\end{bmatrix}_{k-1} +
\begin{bmatrix} ∆x\\ ∆y\\ ∆θ \end{bmatrix}_{k} + \pmb{w}_k
$$

这是简单的线性关系。不过，并不是所有的传感器都直接能测量出位移和角度变化，所以也存在着其他形式更加复杂的运动方程，那时我们可能需要进行动力学分析。

&emsp;
## 3 应用

>观测方程

关于观测方程，比方说小萝卜携带着一个二维激光传感器。我们知道激光传感器观测一个 2D 路标点时，能够测到两个量：
- $r$：路标点与小萝卜本体之间的距离
- $ϕ$：路标点与小萝卜本体之间的夹角

我们记：
- 路标点： $\pmb{y} = [p_x, p_y]^T$（为保持简洁，省略了下标）

- 观测数据： $z = [r, ϕ]^T$

那么观测方程就具体化为：

$$
\begin{bmatrix} r\\ ϕ\end{bmatrix} = 
\begin{bmatrix} \sqrt{(p_x - x)^2 + (p_y - y)^2}\\ 
arctan(\frac{p_y - y}{p_x - x})\end{bmatrix} + 
\pmb{v}$$

<div align="center">
    <image src="./imgs/2.3-1.png" width = 300>
</div>
&emsp;

考虑视觉 SLAM 时，传感器是相机，那么观测方程就是“对路标点拍摄后，得到了图像中的像素”的过程。这个过程牵涉到相机模型的描述，将在第五讲中详细介绍，这里暂时不细谈。

&emsp;
## 4 总结
可见，针对不同的传感器，这两个方程有不同的参数化形式。如果我们保持通用性，把它们取成通用的抽象形式，那么 SLAM 过程可总结为两个基本方程：
$$\begin{cases}\pmb{x}_k = f(\pmb{x}_{k-1}, \pmb{u}_k, \pmb{w}_k) & 运动方程\\
\pmb{z}_{k,j} = h(\pmb{y}_j, \pmb{x}_k, \pmb{v}_{k,j}) & 观测方程\end{cases} $$

这两个方程描述了最基本的 SLAM 问题：当我们知道
- 运动测量的读数 $\pmb{u}$，
- 传感器的读数 $\pmb{z}$ 

如何求解`定位问题`（估计 $\pmb{x}$）和`建图问题`（估计 $\pmb{y}$）？这时，我们把 SLAM问题建模成了一个状态估计问题：`如何通过带有噪声的测量数据，估计内部的、隐藏着的状态变量`？

状态估计问题的求解，与两个方程的具体形式，以及噪声服从哪种分布有关。我们按照运动和观测方程是否为线性，噪声是否服从高斯分布进行分类，分为
- 线性/非线性
- 高斯/非高斯系统

其中线性高斯系统（Linear Gaussian, LG 系统）是最简单的，它的无偏的最优估计可以由卡尔曼滤波器（Kalman Filter, KF）给出。

而在复杂的非线性非高斯系统（Non-Linear Non-Gaussian，NLNG 系统）中，我们会使用以`扩展卡尔曼滤波器（Extended Kalman Filter, EKF）`和`非线性优化`两大类方法去求解它。

&emsp;
>SLAM 使用的优化方法变迁
- 直至 21 世纪早期，以 EKF 为主的滤波器方法占据了 SLAM 中的主导地位。我们会在工作点处把系统线性化，并以预测——更新两大步骤进行求解（见第九讲）。

    最早的实时视觉 SLAM 系统即是基于 EKF 开发的。随后，为了克服 EKF 的缺点（例如线性化误差和噪声高斯分布假设），人们开始使用粒子滤波器（Particle Filter）等其他滤波器，乃至使用非线性优化的方法。

    时至今日，主流视觉 SLAM 使用以图优化（Graph Optimization）为代表的优化技术进行状态估计。我们认为优化技术已经明显优于滤波器技术，只要计算资源允许，我们通常都偏向于使用优化方法（见第十、十一讲）。

相信读者应该对 SLAM 的数学模型有了大致的理解，然而我们仍需澄清一些问题。首先，我们要说明机器人位置 $\pmb{x}$ 是什么。我们方才说位置是有些模糊的。也许读者能够理解在平面中运动的小萝卜，可以用两个坐标加一个转角的形式将位置参数化。

然而，虽然我的漫画风格有些二次元，小萝卜更多时候是一个三维空间里的机器人。

我们知道三维空间的运动由三个轴构成，所以小萝卜的运动要由三个轴上的平移，以及绕着三个轴的旋转来描述，这一共有六个自由度。那是否意味着我随便用一个 $\mathbb{R}^6$ 中的向量就能描述它了呢？

我们将发现事情并没有那么简单。
- 对六自由度的位姿，如何表达它，如何优化它，都需要一定篇幅来介绍，这将是第三讲和第四讲的主要内容
- 随后，我们要说明在视觉 SLAM 中，观测方程如何参数化。换句话说，空间中的路标点是如何投影到一张照片上的。这需要解释相机的成像模型，我们将在第五章介绍
- 最后，当我们知道了这些信息，怎么求解上述方程？这需要非线性优化的知识，则是第六讲的内容

这些内容组成了本书数学知识的部分。在对它们进行铺垫之后，我们就能仔细讨论视觉里程计、后端优化等更详细的知识了。可以看到，本讲介绍的内容构成了本书的一个提要。如果读者还没有很好地理解上面的概念，不妨回过头再阅读一遍。下面我们就要开始讲程序啦！