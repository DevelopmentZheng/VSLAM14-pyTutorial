&emsp;
# 2.1 引子：小萝卜的例子

## 1 小萝卜机器人

<div align="center">
    <image src="./imgs/2.1-1.png" width = 300>
</div>

作为机器人，我们希望小萝卜能够在房间里自由的移动。不管我在哪里招呼一声，它都会嘀溜溜地走过来。
- 要移动首先得有轮子和电机，所以我们在小萝卜下方安装了轮子（足式机器人步态很复杂我们暂时不考虑）。有了轮子，机器人就能够四处行动了，但不加控制的话，小萝卜不知道行动的目标，只能四处乱走，更糟糕地的情况下会撞上墙损坏自己。
- 为了避免这种情况的发生，我们在它脑袋上安装了一个相机。

有眼睛、大脑和四肢的人类，能够在任意环境里轻松自在地行走、探索，我们（天真地）也觉得机器人能够完成这件事。为了使小萝卜能够探索一个房间，它至少需要知道两件事：
1. 我在什么地方？——定位。
2. 周围环境是什么样？——建图

“定位”和“建图”，可以看成感知的“内外之分”。作为一个“内外兼修”的小萝卜学家，一方面要明白自身的状态（即位置），另一方面也要了解外在的环境（即地图）。当然，解决这两个问题的方法非常之多。比方说，
1. 可以在房间地板上铺设导引线，在墙壁上贴识别二维码
2. 在桌子上放置无线电定位设备
3. 如果在室外，还可以在小萝卜脑袋上安装 GPS 定位设备（像手机或汽车一样）。

&emsp;
## 2 传感器
有了这些东西之后，定位问题是否已经解决了呢？我们不妨把这些传感器分为两类。
>携带于机器人本体
- 这类传感器是携带于机器人本体上的，例如机器人的轮式编码器、相机、激光等等
>安装于环境中
- 这类是安装于环境中的，例如前面讲的导轨、二维码标志等等。安装于环境中的传感设备，通常能够直接测量到机器人的位置信息，简单有效地解决定位问题。

>两者对比
- 由于安装与环境中的传感器必须在环境中设置，在一定程度上限制了机器人的使用范围。比方说，有些地方没有 GPS 信号，有些地方无法铺设导轨，这时怎么做定位呢？我们看到，这类传感器约束了外部环境。只有在这些约束满足时，基于它们的定位方案才能工作。反之，当约束无法满足时，我们就没法进行定位了。所以说，虽然这类传感器简单可靠，但它们无法提供一个普遍的，通用的解决方案。

- 相对的，那些携带于机器人本体上的传感器，比如激光传感器、相机、轮式编码器、惯性测量单元（Inertial Measurement Unit, IMU）等等，它们测到的通常都是一些间接的物理量而不是直接的位置数据。例如，
    - 轮式编码器会测到轮子转动的角度
    - IMU 测量运动的角速度和加速度
    - 相机和激光则读取外部环境的某种观测数据

    我们只能通过一些间接的手段，从这些数据推算自己的位置。虽然这听上去是一种迂回战术，但更明显的好处是，它没有对环境提出任何要求，使得这种定位方案可适用于未知环境。

    回忆前面讨论过的 SLAM 定义，我们在 SLAM 中，非常强调`未知环境`。在理论上，我们没法限制小萝卜的使用环境，这意味着我们没法假设像 GPS 这些外部传感器都能顺利工作。因此，使用携带式的传感器来完成 SLAM 是我们重点关心的问题。特别地，当谈论视觉 SLAM 时，我的意思主要是指如何用相机解决定位和建图问题。
<div align="center">
    <image src="./imgs/2.1-2.png" width = 600>
</div>
&emsp;

## 4 相机

视觉 SLAM 是本书的主题，所以我们尤其关心小萝卜的眼睛能够做些什么事。

SLAM 中使用的相机与我们平时见到的单反摄像头并不是同一个东西。它往往更加简单，不携带昂贵的镜头，以一定速率拍摄周围的环境，形成一个连续的视频流。普通的摄像头能以每秒钟 30 张图片的速度采集图像，高速相机则更快一些。

按照相机的工作方式，我们把相机分为
- 单目（Monocular）
- 双目（Stereo）
- 深度相机（RGB-D）

<div align="center">
    <image src="./imgs/2.1-3.png" width = 300>
</div>
&emsp;

直观看来，单目相机只有一个摄像头，双目有两个，而 RGB-D 原理较复杂，除了能够采集到彩色图片之外，还能读出每个像素离相机的距离。

&emsp;
## 5 相机的分类
### （1）单目相机 

只使用一个摄像头进行 SLAM 的做法称为单目 SLAM（Monocular SLAM）。
>优点
- 这种传感器结构特别的简单、成本特别的低，所以单目 SLAM 非常受研究者关注。你肯定见过单目相机的数据：照片。

>特点
- 照片，本质上是拍照时的场景（Scene），在相机的成像平面上留下的一个投影。它以二维的形式反映了三维的世界。
- 显然，这个过程丢掉了场景的一个维度：也就是所谓的深度（或距离）。在单目相机中，我们无法通过单个图片来计算场景中物体离我们的距离（远近）——之后我们会看到，这个距离将是 SLAM 中非常关键的信息。由于我们人类见过大量的图像，养成了一种天生的直觉，对大部分场景都有一个直观的距离感（空间感），它帮助我们判断图像中物体的远近关系。比如说，我们能够辨认出图像中的物体，并且知道它们大致的大小；比如近处的物体会挡住远处的物体，而太阳、月亮等天体一般在很远的
地方；再如物体受光照后会留下影子等等。这些信息可以都帮助我们判断物体的远近，但
也存在一些情况，这个距离感会失效，这时我们无法判断物体的远近以及它们的真实大小
了。
<div align="center">
    <image src="./imgs/2.1-4.png" width = 400>
</div>
&emsp;

在这张图像中，我们无法仅通过它来判断后面那些小人是真实的人，还是小型模型——除非我们转动视角，观察场景的三维结构。
>缺点
- 在单张图像里，你无法确定一个物体的真实大小。它可能是一个很大但很远的物体，也可能是一个很近但很小的物体。由于近大远小的原因，它们可能在图像中变成同样大小的样子。

>单目 SLAM 原理

由于单目相机只是三维空间的二维投影，所以，如果我们真想恢复三维结构，必须移动相机的视角。在单目 SLAM 中也是同样的原理。我们必须移动相机之后，才能估计它的运动（Motion），同时估计场景中物体的远近和大小，不妨称之为结构（Structure）。那么，怎么估计这些运动和结构呢？

从生活经验中我们知道
- 如果相机往右移动，那么图像里的东西就会往左边移动——这就给我们推测运动带来了信息
- 我们还知道近处的物体移动快，远处的物体则运动缓慢

于是，当相机移动时，这些物体在图像上的运动，形成了视差。通过视差，我们就能定量地判断哪些物体离得远，哪些物体离的近。

然而，即使我们知道了物体远近，它们仍然只是一个相对的值。想象我们在看电影时候，虽然能够知道电影场景中哪些物体比另一些大，但我们无法确定电影里那些物体的“真实尺度”：那些大楼是真实的高楼大厦，还是放在桌上的模型？而摧毁大厦的是真实怪兽，还是穿着特摄服装的演员？

直观地说，如果把相机的运动和场景大小同时放大两倍，单目所看到的像是一样的。同样的，把这个大小乘以任意倍数，我们都将看到一样的景象。这说明了单目 SLAM 估计的轨迹和地图，将与真实的轨迹、地图，相差一个因子，也就是所谓的尺度（Scale）。由于单目 SLAM 无法仅凭图像确定这个真实尺度，所以又称为尺度不确定性。

平移之后才能计算深度，以及无法确定真实尺度，这两件事情给单目 SLAM 的应用造成了很大的麻烦。它们的本质原因是通过单张图像无法确定深度。所以，为了得到这个深度，人们又开始使用双目和深度相机。

&emsp;
### （2）双目相机 (Stereo) 
如果知道了距离，场景的三维结构就可以通过单个图像恢复出来，也就消除了尺度不确定性。

尽管都是为测量距离，但双目相机与深度相机测量深度的原理是不一样的。双目相机由两个单目相机组成，但这两个相机之间的距离（称为基线（Baseline））是已知的。我们通过这个基线来估计每个像素的空间位置——这和人眼非常相似。我们人类可以通过左右眼图像的差异，判断物体的远近，在计算机上也是同样的道理。如果对双目相机进行拓展，也可以搭建多目相机，不过本质上并没有什么不同。

计算机上的双目相机需要大量的计算才能（不太可靠地）估计每一个像素点的深度，相比于人类真是非常的笨拙。

双目相机测量到的深度范围与基线相关。基线距离越大，能够测量到的就越远，所以无人车上搭载的双目通常会是个很大的家伙。双目相机的距离估计是比较左右眼的图像获得的，并不依赖其他传感设备，所以它既可以应用在室内，亦可应用于室外。双目或多目相机的缺点是配置与标定均较为复杂，其深度量程和精度受双目的基线与分辨率限制，而且视差的计算非常消耗计算资源，需要使用 GPU 和 FPGA 设备加速后，才能实时输出整张图像的距离信息。因此在现有的条件下，计算量是双目的主要问
题之一。


### （3）深度相机
又称 RGB-D 相机，在本书中主要使用 RGB-D 这个名称）是 2010 年左右开始兴起的一种相机
>特点
- 可以通过红外结构光或 Time-of-Flight（ToF）原理，像激光传感器那样，通过主动向物体发射光并接收返回的光，测出物体离相机的距离。

>优缺点
- 优点：这部分并不像双目那样通过软件计算来解决，而是通过物理的测量手段，所以相比于双目可节省大量的计算量。
- 缺点：不过，现在多数 RGB-D 相机还存在测量范围窄、噪声大、视野小、易受日光干扰、无法测量透射材质等诸多问题，在 SLAM 方面，主要用于室内 SLAM，室外则较难应用。


目前常用的 RGB-D 相机包括 Kinect/Kinect V2、Xtion live pro、Realsense 等。

现在，想象相机在场景中运动的过程，我们将得到一系列连续变化图像。视觉 SLAM 的目标，是通过这样的一些图像，进行定位和地图构建。

这件事情并没有我们想象的那么简单。它不是某种算法，只要我们输入数据，就可以往外不断地输出定位和地图信息了。SLAM 需要一个完善的算法框架，而经过研究者们长期的研究工作，现有这个框架已经定型了。