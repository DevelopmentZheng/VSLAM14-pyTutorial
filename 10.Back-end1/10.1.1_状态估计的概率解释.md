&emsp;
# 状态估计的概率解释
- 前端：视觉里程计 VO 只有短暂的记忆，局部的概念
- 后端：我们希望整个运动轨迹在较长时间内都能保持最优的状态，全局的概念

    用最新的得到的信息，更新较久远之前的状态（位姿），就是后端优化。后端优化对整体的地图构建、定位准确度很重要。

    >批量的（Batch）
    - 在后端优化中，我们通常考虑一个更长时间内（或所有时间内）的状态估计问题，而且不仅使用过去的信息更新自己的状态，也会用未来的信息来更新自己，这种处理方式称为 `批量的（Batch）`

    >渐进的（Incremental）
    - 如果当前的状态只由过去的时刻决定，甚至只由前一个时刻决定，这种处理方式称为 `渐进的（Incremental）`

&emsp;
## 1 VO 前端的状态估计
- 我们已经知道 SLAM 过程可以由运动方程和观测方程来描述。那么，假设在 $t = 0$ 到 $t = N$ 的时间内，我们有 $\pmb{x}_0$ 到 $\pmb{x}_N$ 那么多个位姿，并且有 $\pmb{y}_1, . . . , \pmb{y}_M$ 那么多个路标。按照之前的写法，运动和观测方程为：

    $$\begin{cases}
    \pmb{x}_k = f(\pmb{x}_{k-1}，\pmb{u}_k) + \pmb{w}_k \\
    \pmb{z}_{k,j} = h(\pmb{y}_j，\pmb{x}_k) + \pmb{v}_{k,j}
    \end{cases} \qquad k=1,...,N，j=1,...,M$$

    注意以下几点：
    1. 观测方程中，只有当 $\pmb{x}_k$ 看到了 $\pmb{y}_j$ 时，才会产生观测数据，否则就没有。事实上，在一个位置通常只能看到一小部分路标。而且，由于视觉 SLAM 特征点数量众多，所以实际当中观测方程数量会远远大于运动方程的数量。

    2. 我们可能没有测量运动的装置，所以也可能没有运动方程。在这个情况下，有若干种处理方式：
        - 认为确实没有运动方程
        - 或假设相机不动
        - 或假设相机匀速运动
        
        这几种方式都是可行的。在没有运动方程的情况下，整个优化问题就只由许多个观测方程组成。这就非常类似于 `SfM（Structure from Motion）` 问题，相当于我们通过一组图像来恢复运动和结构。与 SfM 中不同的是，SLAM 中的图像有时间上的先后顺序，而 SfM 中允许使用完全无关的图像。

    我们知道每个方程都受噪声影响，所以要把这里的位姿 $x$ 和路标 $y$ 看成服从某种概率分布的随机变量，而不是单独的一个数。因此，我们关心的问题就变成了：
    - 当我拥有某些 `运动数据 u` 和 `观测数据 z` 时，如何来确定状态量 $x， y$ 的分布？
    - 进而，如果得到了新来时刻的数据之后，那么它们的分布又将发生怎样的变化？

    >均值与协方差
    - 在比较常见且合理的情况下，我们假设状态量和噪声项服从高斯分布——意味着在程序中，只需要储存它们的 `均值` 和 `协方差` 矩阵即可。
        - 均值可看作是对变量最优值的估计
        - 协方差矩阵则度量了它的不确定性

    那么，问题转变为：当存在一些运动数据和观测数据时，我们如何去估计状态量的高斯分布？

&emsp;
## 2 机器人的例子
- 我们依然设身处地地扮演一下小萝卜。只有运动方程时，相当于我们蒙着眼睛在一个
未知的地方走路。尽管我们知道自己每一步走了多远，但是随着时间增长，我们将对自己的位置越来越不确定——内心也就越加不安。这说明在输入数据受噪声影响时，我们对位置方差的估计将越来越大。但是，当我们睁开眼睛时，由于能够不断地观测到外部场景，使得位置估计的不确定性变小了，我们就会越来越自信。

    如果用椭圆或椭球直观地表达协方差阵，那么这个过程有点像是在手机地图软件中走路的感觉。以图 10-1 为例，读者可以想象，当没有观测数据时，这个圆会随着运动越来越大；而如果有正确观测的话，圆就会缩小至一定的大小，保持稳定。

    <div align="center">
        <image src="./imgs/10.1-1.png" width = 600>
    </div>
    &emsp;

    上面的过程以比喻的形式解释了状态估计中的问题，下面我们要以定量的方式来看待它。


&emsp;
## 3 后端的状态估计
- 后端的状态估计优化主要用于校准
    &emsp;
    >重新定义 $\pmb{x}_k$

    - 在第六讲中，我们介绍了最大似然估计，提到把状态估计转换为最小二乘的做法。在本讲我们要更仔细地讨论这个问题。首先，由于 `位姿` 和 `路标点` 都是待估计的变量，我们改变一下记号，令 $\pmb{x}_k$ 为 $k$ 时刻的所有未知量。

        它包含了当前时刻的相机位姿与 $m$ 个路标点。在这种记号的意义下（虽然与之前稍有不同，但含义是清楚的），写成：

        $$\pmb{x}_k \triangleq \{\pmb{x}_k，\pmb{y}_1，...，\pmb{y}_m\}$$

        它包含：
        - $\pmb{x}_k$：当前时刻的相机位姿
        - $\pmb{y}_m$：当前时刻的 $m$ 个路标点

    &emsp;
    >重新定义运动方程和观测方程
    - 同时，把 $k$ 时刻的所有观测记作 $\pmb{z}_k$。于是，运动方程与观测方程的形式可写得更加简洁。这里不会出现 $\pmb{y}$，但我们心里要明白这时 $\pmb{x}$ 中已经包含了之前的 $\pmb{y}$ 了：

    $$\begin{cases}
    \pmb{x}_k = f(\pmb{x}_{k-1}，\pmb{u}_k) + \pmb{w}_k \\
    \pmb{z}_k = h(\pmb{x}_k) + \pmb{v}_k
    \end{cases} \qquad k=1,...,N$$

    - 运动方程
        - $\pmb{x}_k$：相机 $k$ 时刻的位姿
        - $\pmb{x}_{k-1}$：相机 $k-1$ 时刻的位姿
        - $\pmb{u}_k$：是运动传感器的读数（有时也叫输入）
        - $\pmb{w}_k$：噪声
    - 观测方程
        - $\pmb{z}_{k,j}$：观测数据
        - $\pmb{x}_k$：位姿
        - $\pmb{v}_{k,j}$ 是这次观测里的噪声

    &emsp;
    >重新定义状态估计

    - 估计当前状态分布：
        $$P(\pmb{x}_k | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k})$$
        - $\pmb{x}_0$：初始位姿
        - $\pmb{u}_{1:k}$：从 1 到 k 时刻传感器输入的数据
    
        按照 $Bayes$ 法则展开，把 $\pmb{z}_k$ 与 $\pmb{x}_k$ 交换位置，有：

    $$P(\pmb{x}_k | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k}) ∝ 
    P(\pmb{z}_k | \pmb{x}_k) P(\pmb{x}_k | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1})$$

    - 似然：$P(\pmb{z}_k | \pmb{x}_k)$
    - 先验：$P(\pmb{x}_k | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1})$

        似然由观测方程给定，而先验部分，我们要明白当前状态 $\pmb{x}_k$ 是基于过去所有的状态估计得来的。至少，它会受 $\pmb{x}_{k-1}$ 影响，于是按照 $\pmb{x}_{k-1}$ 时刻为条件概率展开：

        $$P(\pmb{x}_k | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1}) = \int P(\pmb{x}_k | \pmb{x}_{k-1}，\pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1})P(\pmb{x}_{k-1} | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1})d\pmb{x}_{k-1}$$

        - $k$ 时刻受先前状态影响：$P(\pmb{x}_k | \pmb{x}_{k-1}，\pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1})$
        - $k-1$ 时刻的状态估计：$P(\pmb{x}_{k-1} | \pmb{x}_0，\pmb{u}_{1:k}，\pmb{z}_{1:k-1})$

        &emsp;

        如果我们考虑更久之前的状态，也可以继续对此式进行展开，但现在我们只关心 $k$ 时刻和 $k - 1$ 时刻的情况。至此，我们给出了贝叶斯估计，虽然上式还没有具体的概率分布形式，所以我还没法实际地操作它。

        对这一步的后续处理，方法上产生了一些分歧。大体来说，存在若干种选择：
        - 其一是假设马尔可夫性，简单的一阶马氏性认为，$k$ 时刻状态只与 $k -1$ 时刻状态有关，而与再之前的无关。如果做出这样的假设，我们就会得到以 `扩展卡尔曼滤波（EKF）`为代表的滤波器方法。在滤波方法中，我们会从某时刻的状态估计，推导到下一个时刻

        - 另外一种方法是依然考虑 $k$ 时刻状态与之前所有状态的关系，此时将得到非线性优化为主体的优化框架。非线性优化的基本知识已经在前文介绍过了。目前视觉 $SLAM$ 主流为非线性优化方法

